{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Project #\n",
    "\n",
    "Include:\n",
    "- Snippets of code\n",
    "- Problematic tags\n",
    "- Visualizations if appropriate\n",
    "\n",
    "## Section 1: Problems encountered in the map\n",
    "\n",
    "### 1a: Audit of 'tag' elements\n",
    "\n",
    "To develop a rough sense of the data contained in the 'tag' elements of nodes, ways, and relations in the OSM file, a script was run to compile and count each unique 'key' in the tag elements. In total, 446 unique keys were present. After performing a cursory scan of the keys by eye, at least three large clusters became evident: (i) tags with 'tiger' data, (ii) tags with 'gnis' data, and (iii) tags labeled with 'fixme'. From the lessons, the possibility of keys with problematic characters was also evident. Consequently, the tag elements were broken down into the following five categories and counted:\n",
    "\n",
    "problem: 1  \n",
    "fixme: 36  \n",
    "gnis: 1873  \n",
    "tiger: 61901  \n",
    "other: 90291  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Section 2: Overview of the data\n",
    "\n",
    "## Section 3: Other ideas about the dataset\n",
    "\n",
    "Notes:\n",
    " - Aggregate keys once for efficiency (done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "filename = 'Rochester.osm'\n",
    "\n",
    "def is_node(element):\n",
    "    return element.tag == 'node'\n",
    "\n",
    "def is_way(element):\n",
    "    return element.tag == 'way'\n",
    "\n",
    "def is_relation(element):\n",
    "    return element.tag == 'relation'\n",
    "\n",
    "def is_tag(element):\n",
    "    return element.tag == 'tag'\n",
    "\n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print \"%s: %d\" % (k, v)\n",
    "        \n",
    "def iter_elements(filename, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "    context = ET.iterparse(filename, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixme: 36\n",
      "gnis: 1873\n",
      "other: 90291\n",
      "problem: 1\n",
      "tiger: 61901\n"
     ]
    }
   ],
   "source": [
    "def aggregate_tag_keys(filename):\n",
    "    keys = defaultdict(int)\n",
    "    for element in iter_elements(filename):\n",
    "        for subelement in element:\n",
    "            if (subelement.tag == 'tag') and ('k' in subelement.attrib):\n",
    "                keys[subelement.get('k')] += 1\n",
    "    return keys\n",
    "\n",
    "def find_problem_tags(filename):\n",
    "    problem_keys = defaultdict(int)\n",
    "    problem_chars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "    keys = aggregate_tag_keys(filename)\n",
    "    for key in keys:\n",
    "        if problem_chars.search(key):\n",
    "            problem_keys[key] += 1\n",
    "    return problem_keys\n",
    "    \n",
    "def categorize_tags(filename):\n",
    "    problem_chars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "    key_categories = {'fixme':0, 'tiger':0, 'gnis':0, 'problem':0, 'other':0}\n",
    "    keys = aggregate_tag_keys(filename)\n",
    "    for key in keys:\n",
    "        if problem_chars.search(key):\n",
    "            key_categories['problem'] += keys[key]\n",
    "        elif ('FIXME' in key) or ('fixme' in key):\n",
    "            key_categories['fixme'] += keys[key]\n",
    "        elif 'tiger' in key:\n",
    "            key_categories['tiger'] += keys[key]\n",
    "        elif 'gnis' in key:\n",
    "            key_categories['gnis'] += keys[key]\n",
    "        else:\n",
    "            key_categories['other'] += keys[key]\n",
    "    return key_categories\n",
    "\n",
    "print_sorted_dict(categorize_tags(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr:city: 2727\n",
      "addr:city_1: 2\n",
      "addr:country: 1992\n",
      "addr:floor: 2\n",
      "addr:floot: 1\n",
      "addr:housename: 31\n",
      "addr:housenumber: 3144\n",
      "addr:housenumber_1: 33\n",
      "addr:housenumber_2: 4\n",
      "addr:housenumber_3: 4\n",
      "addr:housenumber_4: 4\n",
      "addr:housenumber_5: 4\n",
      "addr:place: 1\n",
      "addr:postcode: 2799\n",
      "addr:province: 1\n",
      "addr:state: 2410\n",
      "addr:street: 3249\n",
      "addr:street_1: 3\n",
      "addr:street_2: 1\n",
      "addr:street_3: 1\n",
      "addr:unit: 3\n",
      "address: 14\n"
     ]
    }
   ],
   "source": [
    "def aggregate_addr_tags(filename):\n",
    "    addr_keys = defaultdict(int)\n",
    "    keys = aggregate_tag_keys(filename)\n",
    "    for key in keys:\n",
    "        if 'addr' in key:\n",
    "            addr_keys[key] += keys[key]\n",
    "    return addr_keys\n",
    "\n",
    "addr_keys = aggregate_addr_tags(filename)\n",
    "print_sorted_dict(addr_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr:city_1: 2\n",
      "addr:housenumber_1: 33\n",
      "addr:housenumber_2: 4\n",
      "addr:housenumber_3: 4\n",
      "addr:housenumber_4: 4\n",
      "addr:housenumber_5: 4\n",
      "addr:street_1: 3\n",
      "addr:street_2: 1\n",
      "addr:street_3: 1\n"
     ]
    }
   ],
   "source": [
    "def addr_key_w_num(filename):\n",
    "    addr_w_num = defaultdict(int)\n",
    "    has_num = re.compile(r'^(addr:)\\w*[0-9]$')\n",
    "    for _, element in ET.iterparse(filename, events=('start',)):\n",
    "        if is_tag(element) and ('k' in element.attrib):\n",
    "            key = element.get('k')\n",
    "            if has_num.search(key):\n",
    "                addr_w_num[key] += 1\n",
    "    return addr_w_num\n",
    "print_sorted_dict(addr_key_w_num(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr:city: 2727\n",
      "addr:city_1: 2\n",
      "addr:country: 1992\n",
      "addr:floor: 2\n",
      "addr:floot: 1\n",
      "addr:housename: 31\n",
      "addr:housenumber: 3144\n",
      "addr:housenumber_1: 33\n",
      "addr:housenumber_2: 4\n",
      "addr:housenumber_3: 4\n",
      "addr:housenumber_4: 4\n",
      "addr:housenumber_5: 4\n",
      "addr:place: 1\n",
      "addr:postcode: 2799\n",
      "addr:province: 1\n",
      "addr:state: 2410\n",
      "addr:street: 3249\n",
      "addr:street_1: 3\n",
      "addr:street_2: 1\n",
      "addr:street_3: 1\n",
      "addr:unit: 3\n",
      "*****\n",
      "111 West Elm Street, East Rochester, NY 14445\n",
      "971 South Avenue, Rochester, NY 14620\n",
      "809 Monroe Avenue, Rochester, NY 14607\n",
      "12 Bronson Avenue, Rochester, NY 14608\n",
      "611 N. Winton Road, Rochester, NY 14609\n",
      "956 Lyell Avenu, Rochester, NY 14606\n",
      "939 Bay Street, Rochester, NY 14609\n",
      "851 Joseph Avenue, Rochester, NY 14621\n",
      "1111 Dewey Avenue, Rochester, NY 14613\n",
      "2180 Ridge Road East, Rochester, NY 14622\n",
      "45 Cooper Road, Rochester, NY 14617\n",
      "2780 Dewey Avenue, Rochester, NY 14616\n",
      "3615 Lake Avenue, Rochester, NY 14612\n",
      "115 South Avenue, Rochester, NY 14604\n"
     ]
    }
   ],
   "source": [
    "def count_addr_keys(filename):\n",
    "    addr_keys = defaultdict(int)\n",
    "    has_addr = re.compile(r'^(addr:)')\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if is_tag(element) and ('k' in element.attrib):\n",
    "            key = element.get('k')\n",
    "            if has_addr.search(key):\n",
    "                addr_keys[key] += 1\n",
    "    return addr_keys\n",
    "print_sorted_dict(count_addr_keys(filename))\n",
    "\n",
    "def weird_one(filename):\n",
    "    weird_key = \"address\"\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if is_tag(element) \\\n",
    "        and ('k' in element.attrib) \\\n",
    "        and (element.get('k') == weird_key):\n",
    "            print element.get('v')                                                 \n",
    "print '*****'\n",
    "weird_one(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Road W\n",
      "Winton Road N\n",
      "GBC PW\n",
      "2: 1\n",
      "92: 1\n",
      "Apartment: 1\n",
      "ave: 1\n",
      "Ave: 7\n",
      "Avenue: 531\n",
      "Bl: 1\n",
      "Blvd: 7\n",
      "Boulevard: 12\n",
      "Bridge: 6\n",
      "Cir: 1\n",
      "Circle: 138\n",
      "Court: 60\n",
      "Ct: 1\n",
      "Dr: 9\n",
      "Drive: 951\n",
      "East: 16\n",
      "Green: 5\n",
      "Landing: 1\n",
      "Lane: 428\n",
      "line: 1\n",
      "Manor: 9\n",
      "Market: 1\n",
      "N: 1\n",
      "North: 3\n",
      "NY: 1\n",
      "Oaks: 1\n",
      "Park: 4\n",
      "Parkway: 41\n",
      "Passage: 20\n",
      "Pkwy: 1\n",
      "Place: 12\n",
      "PW: 1\n",
      "Rd: 4\n",
      "Reserve: 1\n",
      "Road: 683\n",
      "South: 25\n",
      "Square: 1\n",
      "St: 5\n",
      "Stree: 1\n",
      "Street: 111\n",
      "Trail: 46\n",
      "Villas: 10\n",
      "W: 1\n",
      "Way: 45\n",
      "West: 41\n",
      "Woods: 2\n"
     ]
    }
   ],
   "source": [
    "def aggregate_street_abbrevs(filename):\n",
    "    streets = defaultdict(int)\n",
    "    street_tag = re.compile(r'^(addr:street)\\w*')\n",
    "    street_name = re.compile(r'\\b\\w+\\b$')\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if is_tag(element) and ('k' in element.attrib):\n",
    "            key = element.get('k')\n",
    "            if street_tag.search(key):\n",
    "                street = street_name.search(element.get('v'))\n",
    "                if street:\n",
    "                    streets[street.group()] += 1\n",
    "                    if street.group() in ('N', 'S', 'E', 'W', 'PW'):\n",
    "                        print element.get('v')\n",
    "    return streets\n",
    "\n",
    "print_sorted_dict(aggregate_street_abbrevs(filename))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Smith Drive\n"
     ]
    }
   ],
   "source": [
    "street = '10 Smith Dr'\n",
    "\n",
    "def fix_street_abbrevs(street):\n",
    "    mapping = {\n",
    "        'ave': 'Avenue',\n",
    "        'Ave': 'Avenue',\n",
    "        'Avenu': 'Avenue',\n",
    "        'Bl': 'Boulevard',\n",
    "        'Blvd': 'Boulevard',\n",
    "        'Cir': 'Circle',\n",
    "        'Ct': 'Court',\n",
    "        'Dr': 'Drive',\n",
    "        'line': 'Line',\n",
    "        'Pkwy': 'Parkway',\n",
    "        'PW': 'Parkway',\n",
    "        'Rd': 'Road',\n",
    "        'St': 'Street',\n",
    "        'Stree': 'Street',\n",
    "        'N': 'North',\n",
    "        'S': 'South',\n",
    "        'E': 'East',\n",
    "        'W': 'West'\n",
    "    }\n",
    "    \n",
    "    elements = street.split()\n",
    "    for i in range(len(elements)):\n",
    "        if elements[i] in mapping:\n",
    "            elements[i] = mapping[elements[i]]\n",
    "    updated_street = ' '.join(elements)\n",
    "    return updated_street\n",
    "\n",
    "print fix_street_abbrevs(street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1--: 1\n",
      "14445: 17\n",
      "14450: 1559\n",
      "14526: 4\n",
      "14534: 98\n",
      "14580: 28\n",
      "14604: 17\n",
      "14605: 3\n",
      "14606: 17\n",
      "14607: 40\n",
      "14608: 1\n",
      "14609: 12\n",
      "14610: 36\n",
      "14611: 1\n",
      "14612: 15\n",
      "14613: 3\n",
      "14614: 9\n",
      "14615: 7\n",
      "14616: 86\n",
      "14617: 7\n",
      "14617-1822: 1\n",
      "14618: 371\n",
      "14620: 22\n",
      "14620-1327: 1\n",
      "14621: 10\n",
      "14622: 5\n",
      "14623: 340\n",
      "14624: 31\n",
      "14624-4721: 1\n",
      "14625: 7\n",
      "14626: 41\n",
      "14627: 3\n",
      "14692: 1\n",
      "14694: 3\n",
      "West Main Street: 1\n"
     ]
    }
   ],
   "source": [
    "def aggregate_zips(filename):\n",
    "    zips = defaultdict(int)\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if is_tag(element) \\\n",
    "        and ('k' in element.attrib) \\\n",
    "        and (element.get('k') == 'addr:postcode'):\n",
    "            key = element.get('v')\n",
    "            zips[key] += 1\n",
    "    return zips\n",
    "\n",
    "print_sorted_dict(aggregate_zips(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to database ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "OSM_PATH = \"Rochester.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, lower_colon=LOWER_COLON, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in node_attr_fields:\n",
    "                node_attribs[attrib] = element.attrib[attrib]\n",
    "        for subtag in element:\n",
    "            temp_attrib = {}\n",
    "            if subtag.tag == 'tag':\n",
    "                #print subtag.attrib\n",
    "                temp_attrib['id'] = node_attribs['id']\n",
    "                temp_attrib['type'] = default_tag_type\n",
    "                temp_attrib['value'] = subtag.get('v')\n",
    "                key = subtag.get('k')\n",
    "                if problem_chars.search(key):\n",
    "                    continue\n",
    "                elif LOWER_COLON.search(key):\n",
    "                    key_segments = key.split(':')\n",
    "                    temp_attrib['type'] = key_segments[0]\n",
    "                    temp_attrib['key'] = ':'.join(key_segments[1:])\n",
    "                else:\n",
    "                    temp_attrib['key'] = key\n",
    "                #print temp_attrib\n",
    "                tags.append(temp_attrib)\n",
    "    if element.tag == 'way':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in way_attr_fields:\n",
    "                way_attribs[attrib] = element.attrib[attrib]\n",
    "        print way_attribs\n",
    "        i = 0\n",
    "        for subtag in element:\n",
    "            temp_attrib = {}\n",
    "            if subtag.tag == 'tag':\n",
    "                #print subtag.attrib\n",
    "                temp_attrib['id'] = way_attribs['id']\n",
    "                temp_attrib['type'] = default_tag_type\n",
    "                temp_attrib['value'] = subtag.get('v')\n",
    "                key = subtag.get('k')\n",
    "                if problem_chars.search(key):\n",
    "                    continue\n",
    "                elif LOWER_COLON.search(key):\n",
    "                    key_segments = key.split(':')\n",
    "                    temp_attrib['type'] = key_segments[0]\n",
    "                    temp_attrib['key'] = ':'.join(key_segments[1:])\n",
    "                else:\n",
    "                    temp_attrib['key'] = key\n",
    "                print temp_attrib\n",
    "                tags.append(temp_attrib)\n",
    "            if subtag.tag == 'nd':\n",
    "                temp_attrib['id'] = way_attribs['id']\n",
    "                temp_attrib['node_id'] = subtag.get('ref')\n",
    "                temp_attrib['position'] = i\n",
    "                way_nodes.append(temp_attrib)\n",
    "                i += 1\n",
    "                print temp_attrib\n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "    if element.tag == 'node':\n",
    "        #print 'node:', node_attribs, 'node_tags:', tags\n",
    "        #pprint.pprint({'node': node_attribs, 'node_tags': tags})\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        #pprint.pprint({'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags})\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-df319fe88986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# Note: Validation is ~ 10X slower. For the project consider using a small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;31m# sample of the map when validating.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mprocess_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOSM_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-df319fe88986>\u001b[0m in \u001b[0;36mprocess_map\u001b[0;34m(file_in, validate)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                     \u001b[0mvalidate_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'node'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-df319fe88986>\u001b[0m in \u001b[0;36mvalidate_element\u001b[0;34m(element, validator, schema)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSCHEMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;34m\"\"\"Raise ValidationError if element does not match schema\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mmessage_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\nElement of type '{0}' has the following errors:\\n{1}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/cerberus/validator.pyc\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, document, schema, update, normalize)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unrequired_by_excludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__normalize_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/cerberus/validator.pyc\u001b[0m in \u001b[0;36m__init_processing\u001b[0;34m(self, document, schema)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefinitionSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_unknown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/cerberus/schema.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, validator, schema)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/cerberus/schema.pyc\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, schema)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0m_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_hash\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_valid_schemas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/cerberus/utils.pyc\u001b[0m in \u001b[0;36mmapping_hash\u001b[0;34m(schema)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmapping_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping_to_frozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/cerberus/utils.pyc\u001b[0m in \u001b[0;36mmapping_to_frozenset\u001b[0;34m(mapping)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping_to_frozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/cerberus/utils.pyc\u001b[0m in \u001b[0;36mmapping_to_frozenset\u001b[0;34m(mapping)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping_to_frozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/cerberus/utils.pyc\u001b[0m in \u001b[0;36mmapping_to_frozenset\u001b[0;34m(mapping)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping_to_frozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/cerberus/utils.pyc\u001b[0m in \u001b[0;36mmapping_to_frozenset\u001b[0;34m(mapping)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                     \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping_to_frozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/abc.pyc\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mABCMeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_invalidation_counter\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 subtype in cls._abc_negative_cache):\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;31m# Fall back to the subclass check.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "OSM_PATH = \"Rochester.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "\n",
    "def fix_street_abbrevs(street):\n",
    "    '''Expand abbreviations in street names'''\n",
    "    \n",
    "    mapping = {\n",
    "        'ave': 'Avenue',\n",
    "        'Ave': 'Avenue',\n",
    "        'Avenu': 'Avenue',\n",
    "        'Bl': 'Boulevard',\n",
    "        'Blvd': 'Boulevard',\n",
    "        'Cir': 'Circle',\n",
    "        'Ct': 'Court',\n",
    "        'Dr': 'Drive',\n",
    "        'line': 'Line',\n",
    "        'Pkwy': 'Parkway',\n",
    "        'PW': 'Parkway',\n",
    "        'Rd': 'Road',\n",
    "        'St': 'Street',\n",
    "        'Stree': 'Street',\n",
    "        'N': 'North',\n",
    "        'S': 'South',\n",
    "        'E': 'East',\n",
    "        'W': 'West'\n",
    "    }\n",
    "    \n",
    "    elements = street.split()\n",
    "    for i in range(len(elements)):\n",
    "        if elements[i] in mapping:\n",
    "            elements[i] = mapping[elements[i]]\n",
    "    updated_street = ' '.join(elements)\n",
    "    return updated_street\n",
    "\n",
    "\n",
    "def fix_zipcode(zipcode):\n",
    "    '''Check the zipcode for the proper format'''\n",
    "    \n",
    "    zipformat = re.compile(r\"(^[0-9]{5})(-[0-9]{4})?\")\n",
    "    if zipformat.match(zipcode):\n",
    "        return zipcode\n",
    "    else:\n",
    "        return 'fixme'\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, lower_colon=LOWER_COLON, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "\n",
    "    # If the element is a node, extract the appropriate tags with valid keys\n",
    "    if element.tag == 'node':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in node_attr_fields:\n",
    "                node_attribs[attrib] = element.attrib[attrib]\n",
    "        for child in element:\n",
    "            temp_attrib = {}\n",
    "            if child.tag == 'tag':\n",
    "                key = child.get('k')\n",
    "                if problem_chars.search(key):\n",
    "                    continue\n",
    "                elif LOWER_COLON.search(key):\n",
    "                    key_segments = key.split(':')\n",
    "                    temp_attrib['type'] = key_segments[0]\n",
    "                    temp_attrib['key'] = ':'.join(key_segments[1:])\n",
    "                else:\n",
    "                    temp_attrib['key'] = key\n",
    "                temp_attrib['id'] = node_attribs['id']\n",
    "                temp_attrib['type'] = default_tag_type\n",
    "                temp_attrib['value'] = child.get('v')\n",
    "                tags.append(temp_attrib)\n",
    "                \n",
    "    # If the element is a way, extract the appropriate tags with valid keys            \n",
    "    if element.tag == 'way':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in way_attr_fields:\n",
    "                way_attribs[attrib] = element.attrib[attrib]\n",
    "        i = 0\n",
    "        for child in element:\n",
    "            temp_attrib = {}\n",
    "            if child.tag == 'tag':\n",
    "                key = child.get('k')\n",
    "                if problem_chars.search(key):\n",
    "                    continue\n",
    "                elif LOWER_COLON.search(key):\n",
    "                    key_segments = key.split(':')\n",
    "                    temp_attrib['type'] = key_segments[0]\n",
    "                    temp_attrib['key'] = ':'.join(key_segments[1:])\n",
    "                else:\n",
    "                    temp_attrib['key'] = key\n",
    "                temp_attrib['id'] = way_attribs['id']\n",
    "                temp_attrib['type'] = default_tag_type\n",
    "                temp_attrib['value'] = child.get('v')\n",
    "                tags.append(temp_attrib)\n",
    "            if child.tag == 'nd':\n",
    "                temp_attrib['id'] = way_attribs['id']\n",
    "                temp_attrib['node_id'] = child.get('ref')\n",
    "                temp_attrib['position'] = i\n",
    "                way_nodes.append(temp_attrib)\n",
    "                i += 1\n",
    "   \n",
    "    # Clean the element's tags\n",
    "    for tag in tags:\n",
    "        \n",
    "        # Expand abbreviations in address fields\n",
    "        if (tag['key'] == 'address') or \\\n",
    "           (tag['key'] == 'addr' and 'street' in tag['type']):\n",
    "            tag['value'] = fix_street_abbrevs(tag['value'])\n",
    "        \n",
    "        # Replace invalid zipcodes with 'fixme'\n",
    "        if (tag['key'] in ('zip_left', 'zip_right')) or \\\n",
    "           (tag['key'] == 'addr' and tag['type'] == 'postcode'):\n",
    "            tag['value'] = fix_zipcode(tag['value'])\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    # Shape the element for integration into the database            \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'street' in 'street_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
