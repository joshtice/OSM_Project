{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Project \n",
    "\n",
    "The objective of this OpenStreetMap (OSM) project is to audit and clean OSM data from the Greater Rochester, NY, area. This region is of particular interest because it is where I was born and where I lived for the first eighteen years of my life. The raw data was downloaded from OSM via the Overpass API and was saved as 'Rochester.osm'. The size of the file is 53.6 MB. The data was processed and interrogated with a series of four scripts, summarized below:\n",
    "\n",
    "* **audit_tags.py**: Summarize and categorize the data in 'tag' elements in the OSM file. Audit tags that contain (i) problematic characters, (ii) street addresses, and (iii) zip codes\n",
    "* **osm_to_csv.py**: Clean the OSM data and transfer to .csv files\n",
    "* **csv_to_database.py**: Define the schema for a SQL database and upload the data from the previously created .csv files\n",
    "* **sql_queries**: Extract information from the database with SQL queries\n",
    "\n",
    "---\n",
    "\n",
    "## Section 1: Problems encountered in the map\n",
    "\n",
    "### 1a: Cursory audit of 'tag' elements\n",
    "\n",
    "To develop a rough sense of the data contained in the 'tag' elements of nodes, ways, and relations in the OSM file, the audit_tags.py script was run to summarize the contents of the 'tag' elements. In total, the OSM file contained 154,102 tag elements. In these elements, 446 _unique_ keys were present. After performing a cursory scan of the unique keys by eye, at least three large clusters were evident: (i) tags with 'tiger' data, (ii) tags with 'gnis' data, and (iii) tags labeled with 'fixme'. A fourth category was investigated, namely those tags that had keys with problematic characters as defined in one of the Udacity lessons (_Case study: OpenStreetMap data [SQL] / Quiz: Tag types_). All other keys were classified as 'other'. The tag elements were segmented into the five categories and counted programmatically, yielding the results in Table 1:\n",
    "\n",
    "|Category |Number of keys          |Fraction of total|\n",
    "|:--------|:----------------------:|----------------:|\n",
    "|tiger    |61901                   |0.402            |\n",
    "|gnis     |1873                    |0.012            |\n",
    "|fixme    |36                      |0.000            |\n",
    "|probem   |1                       |0.000            |\n",
    "|other    |90291                   |0.586            |\n",
    "|**TOTAL**|154102                  |1.000            |\n",
    "\n",
    "<p style=\"text-align: center\">\n",
    "  <b>Table 1: Key categories from Rochester.osm</b>\n",
    "</p>\n",
    "\n",
    "Forty percent of the tag data is from the United States Census Bureau's Topologically Integrated Geographic Encoding and Referencing (TIGER) system. According to OSM's wiki regarding [TIGER fixup] [1], a number of issues may be encountered with TIGER data. Since the TIGER database was created for the purpose of guiding census surveys, many of the issues deal with the accuracy of nodes representing roads and boundaries. Also, since the data was uploaded in 2007/2008, some of the data is antiquated. \n",
    "\n",
    "The next largest cluster of data, composing about 1% of the data, is from the United States Geographical Survey's Geographic Names Information System (GNIS). According to OSM's wiki regarding [USGS GNIS] [2], this data was also bulk imported like TIGER data, and hence contains a number of errors. Many of those errors relate to features that no longer exist. \n",
    "\n",
    "While issues with geographic location accuracy and outdated-ness are beyond the scope of this project, three problems were identified that could be addressed programmatically. They were: (1) keys with problematic characters, (2) overabbreviation of street names, and (3) incorrect zip codes.\n",
    "\n",
    "### 1b: Keys with problematic characters\n",
    "\n",
    "To identify keys that contain problematic characters (characters other than alphanumeric and underscore), a regex was run against a dictionary of all the keys aggregated from the OSM file. Only one key was identified with problemmatic characters - 'Hours of Operation' - which contains spaces. During the upload of the OSM data to .csv files (with the osm_to_csv.py script), the spaces were replaced with underscores with a call to the following function:\n",
    "\n",
    "~~~~ python\n",
    "def fix_prob_chars(key):\n",
    "    '''Eliminate problematic characters from keys'''\n",
    "    \n",
    "    if ' ' in key:\n",
    "        new_key = list(key)\n",
    "        for i, char in enumerate(new_key):\n",
    "            if char == ' ':\n",
    "                new_key[i] = '_'\n",
    "    new_key = ''.join(new_key)\n",
    "    return new_key\n",
    "~~~~\n",
    "\n",
    "### 1c: Overabbrevation of street names\n",
    "\n",
    "A larger issue was found with abbreviations in street names. First, a section of the auidit_tags.py script was run to compile all the tags with address-related fields. From that compilation, keys named 'addr:street' were identified as the most relevant. A second process was run to capture the last word at the end of street name strings, similar to the approach in the Udacity lesson _Case study: OpenStreetMap data [SQL] / Auditing Street Names_. After going through the collection of possible abbreviations manually, a mapping dictionary was developed to correlate abbrevations with their full form. During the upload of the OSM data to .csv files with osm_to_csv.py, the street names strings were interrogated for abbreviations, and the abbreviations were expanded:\n",
    "\n",
    "~~~~ python\n",
    "def fix_street_abbrevs(street):\n",
    "    '''Expand abbreviations in street names'''\n",
    "    \n",
    "    mapping = {\n",
    "        'ave': 'Avenue',\n",
    "        'Ave': 'Avenue',\n",
    "        # ...\n",
    "        # See code for complete mapping dict\n",
    "    }\n",
    "    \n",
    "    elements = street.split()\n",
    "    for i in range(len(elements)):\n",
    "        if elements[i] in mapping:\n",
    "            elements[i] = mapping[elements[i]]\n",
    "    updated_street = ' '.join(elements)\n",
    "    return updated_street\n",
    "~~~~\n",
    "\n",
    "### 1d: Incorrect zip codes\n",
    "\n",
    "Finally, the OSM file was audited for correct zip codes. The audit_tags.py script compiled the values of tags with the key 'addr:postcode'. Only two instances were problematic - one with the value '1--', and a second with the value 'West Main Street'. During the conversion to .csv files, both of these zip codes were converted to 'fixme':\n",
    "\n",
    "~~~~ python\n",
    "def fix_zipcode(zipcode):\n",
    "    '''Check the zipcode for the proper format'''\n",
    "    \n",
    "    zipformat = re.compile(r\"(^[0-9]{5})(-[0-9]{4})?\")\n",
    "    if zipformat.match(zipcode):\n",
    "        return zipcode\n",
    "    else:\n",
    "        return 'fixme'\n",
    "~~~~\n",
    "\n",
    "---\n",
    "\n",
    "## Section 2: Overview of the data\n",
    "\n",
    "After loading the partially-cleaned data to a database with csv_to_database.py, a number of summary statistics were compiled with the sql_queries.py script.  \n",
    "\n",
    "### 2a: Total number of unique users\n",
    "Borrowing a query from carlward's [sample_project.md] [3] file on github, 23 unique contributors were identified in the Rochester.osm file: \n",
    "\n",
    "~~~~ python\n",
    "query = '''SELECT COUNT(DISTINCT(subquery.uid))\n",
    "           FROM\n",
    "               (SELECT uid FROM nodes\n",
    "                UNION ALL\n",
    "                SELECT uid FROM ways)\n",
    "           AS subquery;'''\n",
    "~~~~\n",
    "\n",
    "### 2b: List of unique users contributing to nodes\n",
    "A total of 20 unique users contributed to the nodes table, the most prolific being TomHynes with 1,090 contributions:\n",
    "\n",
    "~~~~ python\n",
    "query = '''SELECT user, COUNT(*) AS num\n",
    "           FROM nodes\n",
    "           GROUP BY user\n",
    "           ORDER BY num DESC;'''\n",
    "~~~~\n",
    "\n",
    "### 2c: List of unique users contributng to ways\n",
    "Only 14 unique users contributed to the ways table. Again TomHynes contributed the most entries with a total of 153:\n",
    "\n",
    "~~~~ python\n",
    "query = '''SELECT user, COUNT(*) AS num\n",
    "           FROM ways\n",
    "           GROUP BY user\n",
    "           ORDER BY num DESC;'''\n",
    "~~~~\n",
    "\n",
    "From a search on LinkedIn ([link] [4]), it appears Tom Hynes is a professional GIS programmer/analyst from New York.\n",
    "\n",
    "### 2d: Number of nodes\n",
    "In total, the database contains 4,283 nodes:\n",
    "\n",
    "~~~~ python\n",
    "query = '''SELECT COUNT(*)\n",
    "\t\t   FROM nodes;'''\n",
    "~~~~\n",
    "\n",
    "### 2e: Number of ways\n",
    "The database contains 378 ways:\n",
    "\n",
    "~~~~ python\n",
    "query = '''SELECT COUNT(*)\n",
    "\t\t   FROM ways;'''\n",
    "~~~~\n",
    "\n",
    "### 2f: Number of restaurants\n",
    "Surprisingly, no nodes and only one way were tagged with 'restaurant', reflecting a large deficiency in the data:\n",
    "\n",
    "~~~~ python\n",
    "query = '''SELECT COUNT(*)\n",
    "               FROM nodes_tags\n",
    "               WHERE value LIKE \"%restaurant%\"\n",
    "               GROUP BY id\n",
    "               ;'''\n",
    "               \n",
    "query = '''SELECT COUNT(*)\n",
    "               FROM ways_tags\n",
    "               WHERE value LIKE \"%restaurant%\"\n",
    "               GROUP BY id\n",
    "               ;'''\n",
    "~~~~\n",
    "\n",
    "### 2e: Number of schools\n",
    "Also, only 2 nodes and 1 way were tagged as schools, suggesting that the number of properly labeled buildings in the Rochester.osm file could be expanded significantly:\n",
    "\n",
    "~~~~ python\n",
    "query = '''SELECT COUNT(*)\n",
    "               FROM nodes_tags\n",
    "               WHERE value LIKE \"%school%\"\n",
    "               GROUP BY id;'''\n",
    "               \n",
    "query = '''SELECT COUNT(*)\n",
    "               FROM ways_tags\n",
    "               WHERE value LIKE \"%school%\"\n",
    "               GROUP BY id;'''\n",
    "~~~~\n",
    "\n",
    "### 2f: Number of nodes in ways\n",
    "A number of interesting observations were made by looking at the number of nodes that were associated with each way. To calculate the average number of nodes per way, the following query was executed:  \n",
    "~~~~ python\n",
    "\n",
    "query = '''SELECT AVG(num)\n",
    "               FROM\n",
    "                   (SELECT COUNT(node_id) AS num\n",
    "                    FROM ways_nodes\n",
    "                    GROUP BY id)\n",
    "               AS subquery;'''\n",
    "~~~~\n",
    "\n",
    "Then, to look at the distribution of nodes per way, another query was run:\n",
    "\n",
    "~~~~ python\n",
    "query = '''SELECT COUNT(node_id) AS num\n",
    "\t\t\t   FROM ways_nodes\n",
    "\t\t\t   GROUP BY id\n",
    "\t\t\t   ORDER BY num DESC;'''\n",
    "~~~~\n",
    "\n",
    "After, the data was displayed as a histogram in Figure 1 using matplotlib:  \n",
    "![](figure_1.jpg)\n",
    "<p style=\"text-align: center\">\n",
    "<b>Figure 1: Histogram of the distrubution of the number of nodes per way in Rochester.osm</b>\n",
    "</p>  \n",
    "\n",
    "Immediately, one can see that the distribution is highly right-skewed. The average of 12 nodes per way, but the mode is 4 - leading to a hypothesis that quadrilaterals are the simplest way of representing most man-made structures. In fact, the entire lower end of the distribution shows a high preference for an even number of nodes to be associated with a way, likely due to a propensity for box-shaped artificial structures in the map data. Ways that had a higher number of nodes per way tended to be 'natural' features. For instance, a query was executed to extract the ways with the top number of nodes:\n",
    "\n",
    "~~~~ python\n",
    "query = '''SELECT subquery.id, num, key, value, type\n",
    "\t\t\t   FROM \n",
    "\t\t\t\t   (SELECT id, COUNT(node_id) AS num\n",
    "\t\t\t\t\tFROM ways_nodes\n",
    "\t\t\t\t\tGROUP BY id\n",
    "\t\t\t\t\tORDER BY num DESC\n",
    "\t\t\t\t\tLIMIT 20) AS subquery\n",
    "\t\t\t   JOIN ways_tags\n",
    "\t\t\t   ON subquery.id=ways_tags.id\n",
    "\t\t\t   ORDER BY num DESC\n",
    "\t\t\t   LIMIT 10;'''\n",
    "~~~~\n",
    "\n",
    "The two ways with the highest number of nodes are the east (Figure 2) and west (Figure 3) borders of Irondequoit Bay:\n",
    "\n",
    "![](figure_2.jpg)  \n",
    "<p style=\"text-align: center\">\n",
    "<b>Figure 2: Render of way \\#157188681, the western coast of Irondequoit Bay (Credit: OpenStreetMap)</b>\n",
    "</p> \n",
    "![](figure_3.jpg)  \n",
    "<p style=\"text-align: center\">\n",
    "<b>Figure 2: Render of way \\#313476845, the eastern coast of Irondequoit Bay (Credit: OpenStreetMap)</b>\n",
    "</p> \n",
    "\n",
    "The way with the third highest number of nodes is a footpath on the eastern shore of Irondequoit Bay (Figure 4), which coindidentally happens to be at the end of the street I grew up on - Smith Road.\n",
    "\n",
    "![](figure_4.jpg)  \n",
    "<p style=\"text-align: center\">\n",
    "<b>Figure 4: Render of way \\#430128611, a path on the eastern side of Irondequoit Bay (Credit: OpenStreetMap)</b>\n",
    "</p> \n",
    "\n",
    "---\n",
    "\n",
    "## Section 3: Other ideas about the dataset\n",
    "\n",
    "One of the largest issues with the data set was simply lack of data, _e.g._, only one restaurant being present, whereas the US Census Bureau documented close to 600 in 2012 ([link] [5]). One idea to increase the amount of data would be to set up an 'augmented' reality app that would identify structures that are not present in the OSM database, and offer incentives for scanning in their GPS data. One issue with this approach, however, could be the accuracy with the users' GPS hardware, which would likely be inferior to dedicated GPS systems. Also, incentivizing user activity could be problematic. Perhaps OSM data collection could be combined with some kind of exercise app with rewards for meeting certain movement goals.\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "[1]: http://wiki.openstreetmap.org/wiki/TIGER_fixup \"http://wiki.openstreetmap.org/wiki/TIGER_fixup\"\n",
    "[2]: http://wiki.openstreetmap.org/wiki/USGS_GNIS \"http://wiki.openstreetmap.org/wiki/USGS_GNIS\"\n",
    "[3]: https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md\n",
    "[4]: https://www.linkedin.com/in/thomas-hynes-7ab13049/\n",
    "[5]: https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?src=CF\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
